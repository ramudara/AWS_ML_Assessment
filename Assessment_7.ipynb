{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "7.\tUsing Amazon Comprehend, create a program that analyses a specific English sentence/paragraph and outputs the following â€“ dominant language, list of entities and the category of each entity, key phrases, and sentiment (positive/negative/neutral/mixed). Do it for different sentences/paragraphs to cover all use cases. Submit the program, input sentences/paragraphs, and their corresponding output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "def analyseText():\n",
    "    comprehend = boto3.client(service_name='comprehend', region_name='us-west-2')\n",
    "    text = input(\"Enter the sentence/paragraph to analyse:\")\n",
    "    \n",
    "    language = comprehend.detect_dominant_language(Text = text)\n",
    "    print(\"The dominant language is \" + language['Languages'][0]['LanguageCode'] + \", confidence = \" + str(language['Languages'][0]['Score']))\n",
    "    print()\n",
    "    \n",
    "    entities = comprehend.detect_entities(Text = text, LanguageCode = 'en')\n",
    "    numEntities = len(entities['Entities'])\n",
    "    print(\"Entities:\")\n",
    "    for i in range(0, numEntities):\n",
    "        print(str(i+1) + \". Entity = \" + entities['Entities'][i]['Text'] + \", type = \" + entities['Entities'][i]['Type'] + \", score = \" + str(entities['Entities'][i]['Score']))\n",
    "        \n",
    "    print()\n",
    "    keyPhrases = comprehend.detect_key_phrases(Text = text, LanguageCode = 'en')\n",
    "    numKeyPhrases = len(keyPhrases['KeyPhrases'])\n",
    "    print(\"Key phrases:\")\n",
    "    for i in range(0, numKeyPhrases):\n",
    "        print(str(i+1) + \". Key phrase = \" + keyPhrases['KeyPhrases'][i]['Text'] + \", score = \" + str(keyPhrases['KeyPhrases'][i]['Score']))\n",
    "        \n",
    "    print()\n",
    "    sentiment = comprehend.detect_sentiment(Text = text, LanguageCode = 'en')\n",
    "    topSentiment = sentiment['Sentiment'].title()\n",
    "    print(\"Sentiment = \" + topSentiment)\n",
    "    print(\"Sentiment scores:\")\n",
    "    for key in sentiment['SentimentScore'].keys():\n",
    "        print(key + \": \" + str(sentiment['SentimentScore'][key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output for Positive Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the sentence/paragraph to analyse:I went to Harry Potter movie yesterday. I really enjoyed through out the movie.\n",
      "The dominant language is en, confidence = 0.9904342889785767\n",
      "\n",
      "Entities:\n",
      "1. Entity = Harry Potter, type = TITLE, score = 0.753732442855835\n",
      "2. Entity = yesterday, type = DATE, score = 0.950821042060852\n",
      "\n",
      "Key phrases:\n",
      "1. Key phrase = Harry Potter movie, score = 0.9710224270820618\n",
      "2. Key phrase = yesterday, score = 0.9912189841270447\n",
      "3. Key phrase = the movie, score = 0.86142897605896\n",
      "\n",
      "Sentiment = Positive\n",
      "Sentiment scores:\n",
      "Positive: 0.9350911974906921\n",
      "Mixed: 0.008834983222186565\n",
      "Neutral: 0.05306575819849968\n",
      "Negative: 0.0030079663265496492\n"
     ]
    }
   ],
   "source": [
    "analyseText()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output for Negative Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the sentence/paragraph to analyse:I am really sad that India lost to Australia in 2011 World cup semi final.\n",
      "The dominant language is en, confidence = 0.9783951044082642\n",
      "\n",
      "Entities:\n",
      "1. Entity = India, type = ORGANIZATION, score = 0.5592288374900818\n",
      "2. Entity = Australia, type = LOCATION, score = 0.5542429089546204\n",
      "3. Entity = 2011 World cup, type = EVENT, score = 0.7314731478691101\n",
      "\n",
      "Key phrases:\n",
      "1. Key phrase = India, score = 0.9730844497680664\n",
      "2. Key phrase = Australia, score = 0.993661642074585\n",
      "3. Key phrase = 2011 World cup semi final, score = 0.8406217694282532\n",
      "\n",
      "Sentiment = Neutral\n",
      "Sentiment scores:\n",
      "Positive: 0.018323838710784912\n",
      "Mixed: 0.03138383850455284\n",
      "Neutral: 0.5103548169136047\n",
      "Negative: 0.4399375319480896\n"
     ]
    }
   ],
   "source": [
    "analyseText()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The above sentence is categorized as Neutral even though I gave completely negative sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying another negative sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the sentence/paragraph to analyse:I am upset with the performance of India in 2011 world cup.\n",
      "The dominant language is en, confidence = 0.9823681712150574\n",
      "\n",
      "Entities:\n",
      "1. Entity = India, type = LOCATION, score = 0.8865684866905212\n",
      "2. Entity = 2011, type = DATE, score = 0.9848459959030151\n",
      "\n",
      "Key phrases:\n",
      "1. Key phrase = the performance, score = 0.9827597141265869\n",
      "2. Key phrase = India, score = 0.9997198581695557\n",
      "3. Key phrase = 2011 world cup, score = 0.9856027960777283\n",
      "\n",
      "Sentiment = Negative\n",
      "Sentiment scores:\n",
      "Positive: 0.022968940436840057\n",
      "Mixed: 0.05335918068885803\n",
      "Neutral: 0.17982232570648193\n",
      "Negative: 0.7438495755195618\n"
     ]
    }
   ],
   "source": [
    "analyseText()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output for Mixed Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the sentence/paragraph to analyse:I went to Harry Potter movie yesterday. I really enjoyed through out the movie but lost my mobile somewhere in the theater.\n",
      "The dominant language is en, confidence = 0.9853095412254333\n",
      "\n",
      "Entities:\n",
      "1. Entity = Harry Potter, type = TITLE, score = 0.753732442855835\n",
      "2. Entity = yesterday, type = DATE, score = 0.950821042060852\n",
      "\n",
      "Key phrases:\n",
      "1. Key phrase = Harry Potter movie, score = 0.9710224270820618\n",
      "2. Key phrase = yesterday, score = 0.9912189841270447\n",
      "3. Key phrase = the movie, score = 0.8423061370849609\n",
      "4. Key phrase = my mobile, score = 0.8207698464393616\n",
      "5. Key phrase = the theater, score = 0.8456326723098755\n",
      "\n",
      "Sentiment = Mixed\n",
      "Sentiment scores:\n",
      "Positive: 0.10847096890211105\n",
      "Mixed: 0.5045356154441833\n",
      "Neutral: 0.16278953850269318\n",
      "Negative: 0.2242038995027542\n"
     ]
    }
   ],
   "source": [
    "analyseText()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying some negative sentence with positive words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the sentence/paragraph to analyse:Good Job Air India! You sent me to Hyderabad and my luggage to Chennai.\n",
      "The dominant language is en, confidence = 0.9830522537231445\n",
      "\n",
      "Entities:\n",
      "1. Entity = India, type = LOCATION, score = 0.8242571949958801\n",
      "2. Entity = Hyderabad, type = LOCATION, score = 0.9891841411590576\n",
      "3. Entity = Chennai, type = LOCATION, score = 0.9918421506881714\n",
      "\n",
      "Key phrases:\n",
      "1. Key phrase = Good Job Air India, score = 0.9286690354347229\n",
      "2. Key phrase = Hyderabad, score = 0.9639323353767395\n",
      "3. Key phrase = my luggage, score = 0.9965354800224304\n",
      "4. Key phrase = Chennai, score = 0.9780399203300476\n",
      "\n",
      "Sentiment = Positive\n",
      "Sentiment scores:\n",
      "Positive: 0.9919666051864624\n",
      "Mixed: 0.0005476307705976069\n",
      "Neutral: 0.007441870868206024\n",
      "Negative: 4.3960015318589285e-05\n"
     ]
    }
   ],
   "source": [
    "analyseText()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Wrongly identified the negative sentence as positive due to postive keywords."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
